{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Below is a short, step‐by‐step tutorial for building a simple agent that uses LangGraph together with Anthropic’s API to generate LinkedIn post ideas. This example uses Python and assumes you have your Anthropic API key ready. The tutorial is based on the latest documentation and community examples for both LangGraph and Anthropic’s API."
      ],
      "metadata": {
        "id": "53TVKe3h5p_2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tutorial: Building a LinkedIn Post Ideas Generator Agent\n",
        "\n",
        "## Overview\n",
        "\n",
        "In this tutorial, you will:\n",
        "\n",
        "- Set up your Python environment.\n",
        "- Create a LangGraph that defines a simple state machine.\n",
        "- Integrate Anthropic’s API (using a Claude model) to generate creative post ideas.\n",
        "- Run the agent to interactively generate LinkedIn post ideas.\n",
        "\n",
        "*This example leverages LangGraph to manage the application flow while Anthropic’s LLM (Claude) produces the text.*\n",
        "\n"
      ],
      "metadata": {
        "id": "HOK6U4RErtBj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prerequisites\n",
        "\n",
        "- **Python 3.8+**\n",
        "- **API key for Anthropic**:\n",
        "  - Sign up and obtain your API key from the Anthropic Console [Anthropic Docs](https://docs.anthropic.com/en/api/getting-started)"
      ],
      "metadata": {
        "id": "uPeVPlKf2-8b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Installation of required packages:\n",
        "\n",
        "Run the following command to install LangGraph and Anthropic’s client:"
      ],
      "metadata": {
        "id": "N78XmouL3UVE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U langgraph anthropic langchain_anthropic\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ec0tTTKIm9ve",
        "outputId": "1888080f-09b9-4670-9445-1f4294b7d3bf"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langgraph\n",
            "  Downloading langgraph-0.3.9-py3-none-any.whl.metadata (7.5 kB)\n",
            "Collecting anthropic\n",
            "  Downloading anthropic-0.49.0-py3-none-any.whl.metadata (24 kB)\n",
            "Collecting langchain_anthropic\n",
            "  Downloading langchain_anthropic-0.3.9-py3-none-any.whl.metadata (1.9 kB)\n",
            "Requirement already satisfied: langchain-core<0.4,>=0.1 in /usr/local/lib/python3.11/dist-packages (from langgraph) (0.3.43)\n",
            "Collecting langgraph-checkpoint<3.0.0,>=2.0.10 (from langgraph)\n",
            "  Downloading langgraph_checkpoint-2.0.19-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting langgraph-prebuilt<0.2,>=0.1.1 (from langgraph)\n",
            "  Downloading langgraph_prebuilt-0.1.3-py3-none-any.whl.metadata (5.0 kB)\n",
            "Collecting langgraph-sdk<0.2.0,>=0.1.42 (from langgraph)\n",
            "  Downloading langgraph_sdk-0.1.57-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from anthropic) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from anthropic) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from anthropic) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from anthropic) (0.9.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from anthropic) (2.10.6)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from anthropic) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.10 in /usr/local/lib/python3.11/dist-packages (from anthropic) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->anthropic) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->anthropic) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->anthropic) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->anthropic) (0.14.0)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4,>=0.1->langgraph) (0.3.13)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4,>=0.1->langgraph) (9.0.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4,>=0.1->langgraph) (1.33)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4,>=0.1->langgraph) (6.0.2)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4,>=0.1->langgraph) (24.2)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from langgraph-checkpoint<3.0.0,>=2.0.10->langgraph) (1.1.0)\n",
            "Requirement already satisfied: orjson>=3.10.1 in /usr/local/lib/python3.11/dist-packages (from langgraph-sdk<0.2.0,>=0.1.42->langgraph) (3.10.15)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->anthropic) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->anthropic) (2.27.2)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4,>=0.1->langgraph) (3.0.0)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4,>=0.1->langgraph) (2.32.3)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4,>=0.1->langgraph) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4,>=0.1->langgraph) (0.23.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langsmith<0.4,>=0.1.125->langchain-core<0.4,>=0.1->langgraph) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langsmith<0.4,>=0.1.125->langchain-core<0.4,>=0.1->langgraph) (2.3.0)\n",
            "Downloading langgraph-0.3.9-py3-none-any.whl (132 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.4/132.4 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading anthropic-0.49.0-py3-none-any.whl (243 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m243.4/243.4 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_anthropic-0.3.9-py3-none-any.whl (24 kB)\n",
            "Downloading langgraph_checkpoint-2.0.19-py3-none-any.whl (39 kB)\n",
            "Downloading langgraph_prebuilt-0.1.3-py3-none-any.whl (24 kB)\n",
            "Downloading langgraph_sdk-0.1.57-py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: langgraph-sdk, anthropic, langgraph-checkpoint, langchain_anthropic, langgraph-prebuilt, langgraph\n",
            "Successfully installed anthropic-0.49.0 langchain_anthropic-0.3.9 langgraph-0.3.9 langgraph-checkpoint-2.0.19 langgraph-prebuilt-0.1.3 langgraph-sdk-0.1.57\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 1: Setting Up the Environment\n",
        "\n",
        "First, set your Anthropic API key as an environment variable to ensure it’s accessible by the Anthropic client.\n",
        "\n",
        "If your key is stored in a .env or using Jupyter Notebook locally, you can run as follow:"
      ],
      "metadata": {
        "id": "RGrf0DiH3e_8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"ANTHROPIC_API_KEY\"] = \"your_anthropic_api_key_here\"\n"
      ],
      "metadata": {
        "id": "LBMz0qRC3siE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you are using Google Collab - like I did - and stored the key the 'Secrets'tab, run as follow:"
      ],
      "metadata": {
        "id": "4SzrOH5h3t4V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "ANTHROPIC_API_KEY = userdata.get('ANTHROPIC_API_KEY')\n",
        "api_key = ANTHROPIC_API_KEY"
      ],
      "metadata": {
        "id": "DlWifRjPmiAe"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 2: Creating the LangGraph Agent\n",
        "\n",
        "Define a simple state machine using LangGraph. In this example, we’ll create a node that calls Anthropic’s ChatAnthropic model (Claude) to generate LinkedIn post ideas.\n",
        "\n",
        "Here I used the latest Anthropic's model, claude-3-7-sonnet-20250219; but feel free to change it.\n",
        "\n",
        "Also, to be able to use the API, you need to add some money to your account. More info here: [Anthropic's Website](https://support.anthropic.com/en/articles/8977456-how-do-i-pay-for-my-api-usage)"
      ],
      "metadata": {
        "id": "L19Qr71g4DUm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Annotated\n",
        "from typing_extensions import TypedDict\n",
        "from langgraph.graph import StateGraph, START, END\n",
        "from langgraph.graph.message import add_messages\n",
        "from langchain_anthropic import ChatAnthropic"
      ],
      "metadata": {
        "id": "lfKUHzminE15"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a state schema that holds a list of messages.\n",
        "class State(TypedDict):\n",
        "    messages: Annotated[list, add_messages]"
      ],
      "metadata": {
        "id": "XrvUaDGPnJHR"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize a LangGraph instance with the state.\n",
        "graph_builder = StateGraph(State)\n",
        "\n",
        "# Initialize the Anthropic client (using Claude).\n",
        "llm = ChatAnthropic(model=\"claude-3-7-sonnet-20250219\", anthropic_api_key=api_key)\n"
      ],
      "metadata": {
        "id": "Y1A6qNiEnKQp"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the node function that generates post ideas.\n",
        "def generate_post_ideas(state: State):\n",
        "    # Take the existing conversation history.\n",
        "    conversation = state[\"messages\"]\n",
        "    # Append a query for LinkedIn post ideas.\n",
        "    query = {\"role\": \"user\", \"content\": \"Generate 5 creative LinkedIn post ideas for professional networking.\"}\n",
        "    full_prompt = conversation + [query]\n",
        "    # Get the response from Anthropic.\n",
        "    response = llm.invoke(full_prompt)\n",
        "    return {\"messages\": [response]}"
      ],
      "metadata": {
        "id": "dl2dclDGnblI"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add the node to the graph.\n",
        "graph_builder.add_node(\"post_idea_generator\", generate_post_ideas)\n",
        "# Define the graph flow.\n",
        "graph_builder.add_edge(START, \"post_idea_generator\")\n",
        "graph_builder.add_edge(\"post_idea_generator\", END)\n",
        "\n",
        "# Compile the graph into a runnable object.\n",
        "graph = graph_builder.compile()"
      ],
      "metadata": {
        "id": "NLyzPIdXnkVn"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Explanation:\n",
        "\n",
        "- We create a simple state (holding a list of messages) and a node named \"post_idea_generator\".\n",
        "- The node function appends a specific query to generate post ideas and calls Anthropic’s LLM.\n",
        "- The graph is set up with an entry point and an exit point so that execution stops after the node returns its result."
      ],
      "metadata": {
        "id": "goiKMXqv4u4X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 3: Running the Agent\n",
        "\n",
        "Now, create a simple loop to prompt for user input and display the generated LinkedIn post ideas."
      ],
      "metadata": {
        "id": "YRb-rvgl5Dvp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def run_agent():\n",
        "    print(\"LinkedIn Post Ideas Generator. Type 'quit' to exit.\")\n",
        "    while True:\n",
        "        user_input = input(\"Enter some context or leave blank: \")\n",
        "        if user_input.lower() in [\"quit\", \"exit\", \"q\"]:\n",
        "            print(\"Exiting agent. Goodbye!\")\n",
        "            break\n",
        "        # Initialize the state with the user's input.\n",
        "        initial_state = {\"messages\": [{\"role\": \"user\", \"content\": user_input}]}\n",
        "        # Run the graph and stream the output.\n",
        "        for event in graph.stream(initial_state):\n",
        "            for value in event.values():\n",
        "                print(\"Agent:\", value[\"messages\"][-1].content)\n",
        "\n",
        "run_agent()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k4Ma6nLSnsbr",
        "outputId": "1e638742-1628-4fad-89a9-11ddee83d38a"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LinkedIn Post Ideas Generator. Type 'quit' to exit.\n",
            "Enter some context or leave blank: NLP AND PROBABILISTIC MODELS\n",
            "Agent: # 5 Creative LinkedIn Post Ideas for Professional Networking\n",
            "\n",
            "## 1. \"The NLP Revolution: From Theory to Practice\"\n",
            "Share your journey implementing an NLP model that transformed business outcomes. Include a brief case study with actual results and invite connections to share their own NLP implementation stories. End with a thoughtful question about balancing technical sophistication with practical business value.\n",
            "\n",
            "## 2. \"Probabilistic Models Explained Through Everyday Scenarios\"\n",
            "Create an engaging analogy comparing complex probabilistic concepts to everyday decisions (like choosing lunch options based on past experiences). Include a simple visualization and ask your network how they explain complex statistical concepts to non-technical stakeholders.\n",
            "\n",
            "## 3. \"Weekly NLP Paper Breakdown: What It Means For Industry\"\n",
            "Analyze a recent academic paper in NLP and explain its practical implications for business applications. Tag relevant researchers and companies, then invite discussion about the gap between research advancements and industry implementation.\n",
            "\n",
            "## 4. \"The Hidden Markov Models in My Career Path\"\n",
            "Share a personal career story using probabilistic terminology as metaphors (state transitions between roles, conditional probabilities of success, etc.). Make it both technically accurate and personally authentic, inviting others to reflect on the \"hidden states\" in their own career journeys.\n",
            "\n",
            "## 5. \"AI Ethics Spotlight: When My Model Got It Wrong\"\n",
            "Detail a specific instance where your NLP model produced problematic results, what you learned from it, and how you improved your approach. Frame it as a learning opportunity and invite others to share their \"instructive failures\" in a judgment-free discussion about responsible AI development.\n",
            "Enter some context or leave blank: QUIT\n",
            "Exiting agent. Goodbye!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## How it works:\n",
        "\n",
        "- The agent begins with an initial message (from the user).\n",
        "- It then adds a fixed query asking for LinkedIn post ideas.\n",
        "- Anthropic’s API generates a response, which is printed to the console."
      ],
      "metadata": {
        "id": "J2MNUqTT5U8h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Conclusion\n",
        "\n",
        "You have now built a simple agent using LangGraph and Anthropic’s API to generate creative LinkedIn post ideas.\n",
        "\n",
        "This modular design allows you to expand the agent further by:\n",
        "- Adding more nodes (e.g., for reviewing or editing responses).\n",
        "- Incorporating memory to maintain multi-turn conversations.\n",
        "- Integrating additional tools (such as web search) to enhance idea generation.\n",
        "\n",
        "For further reading:\n",
        "- [Anthropic API Documentation](https://docs.anthropic.com/en/home)\n",
        "- [LangGraph Tutorials and Documentation](https://langchain-ai.github.io/langgraph/tutorials/)\n",
        "Feel free to experiment and customize the agent to suit your specific needs!\n",
        "\n",
        "---\n",
        "\n",
        "This completes this short tutorial for building a LinkedIn post ideas generator agent using LangGraph and Anthropic’s API!"
      ],
      "metadata": {
        "id": "2r4vfkRg5eaN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "wOqZA6gC5A4g"
      }
    }
  ]
}